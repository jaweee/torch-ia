{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "915c02d7",
   "metadata": {},
   "source": [
    "# torch基础\n",
    "\n",
    "1. tensor的分类\n",
    "2. tensor的创建\n",
    "3. tensor的操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c56e6d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d001aa",
   "metadata": {},
   "source": [
    "## 1. tensor的分类"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07478dab",
   "metadata": {},
   "source": [
    "### 标量、向量、矩阵、张量\n",
    "\n",
    "0维tensor、1维tensor、2维tensor、3维tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2c184543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scalar_: 维度为0，形状为torch.Size([])，值为 \n",
      "tensor(7)\n",
      "\n",
      "vector_: 维度为1，形状为torch.Size([2])，值为 \n",
      "tensor([1, 2])\n",
      "\n",
      "matrix_: 维度为2，形状为torch.Size([2, 2])，值为 \n",
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "\n",
      "tensor_: 维度为3，形状为torch.Size([2, 3, 3])，值为 \n",
      "tensor([[[1, 2, 3],\n",
      "         [4, 5, 6],\n",
      "         [7, 8, 9]],\n",
      "\n",
      "        [[1, 2, 3],\n",
      "         [4, 5, 6],\n",
      "         [7, 8, 9]]])\n"
     ]
    }
   ],
   "source": [
    "scalar_ = torch.tensor(7)\n",
    "vector_ = torch.tensor([1,2])\n",
    "matrix_ = torch.tensor([[1,2],[3,4]])\n",
    "tensor_ = torch.tensor([[[1,2,3],[4,5,6],[7,8,9]],[[1,2,3],[4,5,6],[7,8,9]]])\n",
    "print(\"scalar_: 维度为\" + str(scalar_.ndim) + \"，形状为\" + str(scalar_.shape) + \"，值为 \\n\" + str(scalar_))\n",
    "print(\"\\nvector_: 维度为\" + str(vector_.ndim) + \"，形状为\" + str(vector_.shape) + \"，值为 \\n\" + str(vector_))\n",
    "print(\"\\nmatrix_: 维度为\" + str(matrix_.ndim) + \"，形状为\" + str(matrix_.shape) + \"，值为 \\n\" + str(matrix_))\n",
    "print(\"\\ntensor_: 维度为\" + str(tensor_.ndim) + \"，形状为\" + str(tensor_.shape) + \"，值为 \\n\" + str(tensor_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3b8311",
   "metadata": {},
   "source": [
    "## 2. 创建tensor\n",
    "\n",
    "写死、随机、填充0或1、根据范围、根据已有的tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e44ee2",
   "metadata": {},
   "source": [
    "### 随机创建tensor\n",
    "使用torch中的函数来创建**由随机数组成的**tensor、而不是像上面一样，手动指定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "04f185d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.661022961139679\n",
      "\n",
      "\n",
      "tensor([0.2221, 0.7893])\n",
      "\n",
      "\n",
      "tensor([[0.2420, 0.9047],\n",
      "        [0.1931, 0.3477]])\n",
      "\n",
      "\n",
      "tensor([[[0.5290, 0.9812, 0.3706],\n",
      "         [0.1914, 0.5206, 0.4422],\n",
      "         [0.8292, 0.9566, 0.2125]]])\n"
     ]
    }
   ],
   "source": [
    "rand_scalar = torch.rand(size=(1,))\n",
    "rand_vector = torch.rand(size=(2,))\n",
    "rand_matrix = torch.rand(size=(2,2))\n",
    "rand_tensor = torch.rand(size=(1,3,3))\n",
    "print(rand_scalar.item())\n",
    "print(\"\\n\")\n",
    "print(rand_vector)\n",
    "print(\"\\n\")\n",
    "print(rand_matrix)\n",
    "print(\"\\n\")\n",
    "print(rand_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3a48d1",
   "metadata": {},
   "source": [
    "### 创建全0和全1的tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "bf77c165",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 0.]),\n",
       " tensor([1., 1., 1.]),\n",
       " tensor([[0., 0., 0.],\n",
       "         [0., 0., 0.]]),\n",
       " tensor([[1., 1.],\n",
       "         [1., 1.],\n",
       "         [1., 1.]]),\n",
       " tensor([[[0., 0., 0.],\n",
       "          [0., 0., 0.],\n",
       "          [0., 0., 0.]]]),\n",
       " tensor([[[1., 1., 1.],\n",
       "          [1., 1., 1.],\n",
       "          [1., 1., 1.]]]))"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_vector = torch.zeros(size=(2,))\n",
    "one_vector = torch.ones(size=(3,))\n",
    "zero_matrix = torch.zeros(size=(2,3))\n",
    "one_matrix = torch.ones(size=(3,2))\n",
    "zero_tensor = torch.zeros(size=(1,3,3))\n",
    "one_tensor = torch.ones(size=(1,3,3))\n",
    "zero_vector, one_vector, zero_matrix, one_matrix, zero_tensor, one_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67568016",
   "metadata": {},
   "source": [
    "### 根据范围来创建\n",
    "\n",
    "如果不加操作的话，那么创建的就是一个向量而已，但是，可以通过reshape、view、squeeze、unsqueeze来修改tensor的shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c09652af",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = torch.arange(0, 16, 1)\n",
    "re_vector = vector.reshape(4,4)\n",
    "view_vector = vector.view(2,8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7e9aaa",
   "metadata": {},
   "source": [
    "### 根据已有的tensor创建相同shape的tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f875d24a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 0.]),\n",
       " tensor([1., 1.]),\n",
       " tensor([[0., 0.],\n",
       "         [0., 0.]]),\n",
       " tensor([[1., 1.],\n",
       "         [1., 1.]]),\n",
       " tensor([[[1., 1., 1.],\n",
       "          [1., 1., 1.],\n",
       "          [1., 1., 1.]]]),\n",
       " tensor([[[0., 0., 0.],\n",
       "          [0., 0., 0.],\n",
       "          [0., 0., 0.]]]))"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_zl = torch.zeros_like(input=rand_vector)\n",
    "vector_ol = torch.ones_like(input=rand_vector)\n",
    "matrix_zl = torch.zeros_like(input=rand_matrix)\n",
    "matrix_ol = torch.ones_like(input=rand_matrix)\n",
    "tensor_zl = torch.zeros_like(input=rand_tensor)\n",
    "tensor_ol = torch.ones_like(input=rand_tensor)\n",
    "vector_zl, vector_ol, matrix_zl, matrix_ol, tensor_zl, tensor_ol"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6b1e34",
   "metadata": {},
   "source": [
    "### 指定属性创建\n",
    "数据类型dtype、使用的设备device、是否需要记录梯度require_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "76ffc7ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3.], dtype=torch.float16),\n",
       " torch.Size([3]),\n",
       " torch.float16,\n",
       " device(type='cpu'))"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 默认float32、cpu、False\n",
    "\n",
    "float_32_tensor = torch.tensor([1.0, 2.0, 3.0],\n",
    "                              dtype = torch.float16,\n",
    "                              device = None,\n",
    "                              requires_grad = False)\n",
    "\n",
    "float_32_tensor, float_32_tensor.shape, float_32_tensor.dtype, float_32_tensor.device\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47dd331e",
   "metadata": {},
   "source": [
    "## 2. 操作tensor\n",
    "\n",
    "1. 对应元素四则运算\n",
    "2. 矩阵乘法\n",
    "\n",
    "比如最简单的线性回归就会 y = W*x + b, W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "1e3345a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([11, 12])\n",
      "tensor([-9, -8])\n",
      "tensor([0.1000, 0.2000])\n",
      "tensor([10, 20])\n",
      "tensor([1, 4])\n",
      "tensor([[11, 12],\n",
      "        [13, 14]])\n",
      "tensor([[[10.0007, 10.5687, 10.7552],\n",
      "         [10.9824, 10.3315, 10.1534],\n",
      "         [10.1164, 10.5870, 10.7512]],\n",
      "\n",
      "        [[10.1718, 10.5199, 10.4790],\n",
      "         [10.7279, 10.8450, 10.4779],\n",
      "         [10.3379, 10.6586, 10.9703]]])\n",
      "tensor([[[6.9177e-04, 5.6868e-01, 7.5520e-01],\n",
      "         [9.8240e-01, 3.3149e-01, 1.5342e-01],\n",
      "         [1.1643e-01, 5.8698e-01, 7.5120e-01]],\n",
      "\n",
      "        [[1.7183e-01, 5.1995e-01, 4.7896e-01],\n",
      "         [7.2787e-01, 8.4500e-01, 4.7789e-01],\n",
      "         [3.3789e-01, 6.5865e-01, 9.7033e-01]]])\n",
      "tensor([2, 4])\n"
     ]
    }
   ],
   "source": [
    "vector = torch.tensor([1,2])\n",
    "print(vector + 10)\n",
    "print(vector - 10)\n",
    "print(vector / 10)\n",
    "print(vector * 10)\n",
    "print(vector * vector)\n",
    "\n",
    "matrix = torch.tensor([[1,2],[3,4]])\n",
    "print(matrix + 10)\n",
    "\n",
    "tensor = torch.rand(size=(2,3,3))\n",
    "print(tensor + 10)\n",
    "\n",
    "# 可以用scalar替代常量\n",
    "scalar = torch.tensor(2)\n",
    "print(vector * scalar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "b2ee8f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vector: tensor([1, 2])\n",
      "matrix: tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "tensor: tensor([[[6.9177e-04, 5.6868e-01, 7.5520e-01],\n",
      "         [9.8240e-01, 3.3149e-01, 1.5342e-01],\n",
      "         [1.1643e-01, 5.8698e-01, 7.5120e-01]],\n",
      "\n",
      "        [[1.7183e-01, 5.1995e-01, 4.7896e-01],\n",
      "         [7.2787e-01, 8.4500e-01, 4.7789e-01],\n",
      "         [3.3789e-01, 6.5865e-01, 9.7033e-01]]])\n",
      "vector @ vector: tensor(5)\n",
      "matrix[i] @ matrix[i]：tensor(5)\n",
      "matrix[i] @ matrix[i]：tensor(25)\n",
      "matrix @ matrix: tensor([[ 7, 10],\n",
      "        [15, 22]])\n",
      "tensor[i] @ tensor[i]：tensor([[0.6466, 0.6322, 0.6551],\n",
      "        [0.3442, 0.7586, 0.9080],\n",
      "        [0.6642, 0.7017, 0.7423]])\n",
      "\n",
      "tensor[i] @ tensor[i]：tensor([[0.5698, 0.8442, 0.7955],\n",
      "        [0.9016, 1.4072, 1.2161],\n",
      "        [0.8653, 1.3714, 1.4181]])\n",
      "\n",
      "matrix @ vector：tensor([ 7, 10])\n",
      "vector @ matrix：tensor([ 5, 11])\n"
     ]
    }
   ],
   "source": [
    "# 矩阵相乘\n",
    "print(\"vector: \" + str(vector) + \"\\n\" + \"matrix: \" + str(matrix) + \"\\n\" + \"tensor: \" + str(tensor))\n",
    "\n",
    "## 向量相乘，（放在前面就是行向量，放在后面就是列向量）\n",
    "print(\"vector @ vector: \" + str(torch.matmul(vector, vector)))\n",
    "for i in range(matrix.ndim):\n",
    "    print(\"matrix[i] @ matrix[i]：\"+ str(torch.matmul(matrix[i], matrix[i])))\n",
    "    \n",
    "## 矩阵相乘，（tensor.shape[0], 可以得到此tensor中有几个矩阵）\n",
    "print(\"matrix @ matrix: \" + str(torch.matmul(matrix, matrix)))\n",
    "for i in range(tensor.shape[0]):\n",
    "    print(\"tensor[i] @ tensor[i]：\"+ str(torch.matmul(tensor[i], tensor[i])))\n",
    "    print(\"\")\n",
    "\n",
    "## 矩阵与向量相乘，（主要是为了验证是否既可以是列向量也可以是行向量，结果是可以的，也如上所述）\n",
    "print(\"matrix @ vector：\" + str(torch.matmul(vector, matrix)))\n",
    "print(\"vector @ matrix：\" + str(torch.matmul(matrix, vector)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fe1e99",
   "metadata": {},
   "source": [
    "## 3. 对tensor进行聚合\n",
    "\n",
    "\n",
    "最小值、最大值、平均值、求和，（数据库的对此类操作也是用的aggregation）\n",
    "此外，还可以找到最大值和最小值的下标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "20698c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最小值：tensor(1), tensor(1)\n",
      "最大值：tensor(2), tensor(2)\n",
      "平均值：tensor(1.5000), tensor(1.5000)\n",
      "求和：tensor(3), tensor(3)\n",
      "tensor(1),tensor(4),tensor(2.5000),tensor(10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.0007), tensor(0.9824), tensor(0.5242), tensor(9.4349))"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"最小值：\" + str(vector.min())  + \", \" + str(torch.min(vector)))\n",
    "print(\"最大值：\" + str(vector.max())  + \", \" + str(torch.max(vector)))\n",
    "# print(\"平均值：\" + str(aggregation.mean())  + \", \" + str(torch.mean(aggregation)))， ***这个需要将整数的vector转成浮点数***\n",
    "print(\"平均值：\" + str(vector.type(torch.float32).mean())  + \", \" + str(torch.mean(vector.type(torch.float32))))\n",
    "print(\"求和：\" + str(vector.sum()) + \", \" + str(torch.sum(vector)))\n",
    "\n",
    "print(str(matrix.min())+\",\"+ str(matrix.max()) +\",\"+ str(matrix.type(torch.float32).mean()) +\",\"+ str(matrix.sum()))\n",
    "\n",
    "a = torch.tensor([[[1,2,3], [1,2,3], [1,2,3]]])\n",
    "      \n",
    "tensor.min(), tensor.max(), tensor.type(torch.float32).mean(), tensor.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "1d1aaf65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vector的最小值和最大值下标：(tensor([1, 2]), 0, 1)\n",
      "matrix的最小值和最大值下标：(tensor([[1, 2],\n",
      "        [3, 4]]), 0, 3)\n",
      "tensor的最小值和最大值下标：(tensor([[[6.9177e-04, 5.6868e-01, 7.5520e-01],\n",
      "         [9.8240e-01, 3.3149e-01, 1.5342e-01],\n",
      "         [1.1643e-01, 5.8698e-01, 7.5120e-01]],\n",
      "\n",
      "        [[1.7183e-01, 5.1995e-01, 4.7896e-01],\n",
      "         [7.2787e-01, 8.4500e-01, 4.7789e-01],\n",
      "         [3.3789e-01, 6.5865e-01, 9.7033e-01]]]), 0, 3)\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "\n",
    "vector_display = vector, vector.argmin().item(), vector.argmax().item()\n",
    "\n",
    "matrix_display = matrix, matrix.argmin().item(), matrix.argmax().item()\n",
    "\n",
    "tensor_display = tensor, tensor.argmin().item(), tensor.argmax().item()\n",
    "\n",
    "print(\"vector的最小值和最大值下标：\" + str(vector_display))\n",
    "print(\"matrix的最小值和最大值下标：\" + str(matrix_display))\n",
    "print(\"tensor的最小值和最大值下标：\" + str(tensor_display))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68a677f",
   "metadata": {},
   "source": [
    "## 修改tensor\n",
    "\n",
    "1. 修改tensor的数据类型\n",
    "2. 修改tensor的形状（reshape、view、squeeze、unsqueeze）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "09e5ef66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2.])"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 修改tensor的数据类型， \n",
    "vector.type(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "09ecf587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1],\n",
       "         [ 2,  3]],\n",
       "\n",
       "        [[ 4,  5],\n",
       "         [ 6,  7]],\n",
       "\n",
       "        [[ 8,  9],\n",
       "         [10, 11]],\n",
       "\n",
       "        [[12, 13],\n",
       "         [14, 15]]])"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 修改固定的向量为矩阵、张量，也就是修改tensor的形状\n",
    "a_v = torch.arange(0,16,1)\n",
    "a_m = a_v.reshape(4, 4)\n",
    "a_t = a_m.reshape(2,2,4)\n",
    "a_m = a_t.reshape(2, 8)\n",
    "\n",
    "## 除了reshape，还有view\n",
    "a_m = a_v.view(8, 2)\n",
    "a_t = a_v.view(4, 2, 2)\n",
    "\n",
    "## 这两者的区别是，reshape有可能会进行深拷贝，而不是想view是会进行浅拷贝\n",
    "## 可以通过对数据进行修改，来验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04ab3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 复制tensor"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
